import streamlit as st
from langchain_core.messages import HumanMessage, AIMessage
from src.cores.CoT_agent import NutriAgentReseacher

# --- 1. Cáº¤U HÃŒNH TRANG ---
st.set_page_config(
    page_title="NutriAgent Chat",
    page_icon="ğŸ¥—",
    layout="centered",
    initial_sidebar_state="expanded"
)

# --- 2. CSS TÃ™Y CHá»ˆNH (GIAO DIá»†N Sáº CH Sáº¼) ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Inter', sans-serif;
    }
    
    /* áº¨n bá»›t cÃ¡c element thá»«a */
    header {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* Input Chat */
    .stChatInputContainer textarea {
        border-radius: 12px;
        border: 1px solid #e5e7eb;
    }

    /* TiÃªu Ä‘á» */
    .header-container {
        text-align: center;
        margin-bottom: 30px;
    }
    .header-title {
        font-size: 36px;
        font-weight: 800;
        background: -webkit-linear-gradient(45deg, #059669, #34D399);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin: 0;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. HÃ€M HELPER CHUYá»‚N Äá»”I Lá»ŠCH Sá»¬ ---
def convert_history_to_langchain(streamlit_msgs):
    """
    Chuyá»ƒn Ä‘á»•i format chat cá»§a Streamlit sang format LangChain hiá»ƒu Ä‘Æ°á»£c.
    """
    history = []
    for msg in streamlit_msgs:
        if msg["role"] == "user":
            history.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            history.append(AIMessage(content=msg["content"]))
    return history

# --- 4. KHá»I Táº O AGENT (QUáº¢N LÃ CACHE THÃ”NG MINH) ---
@st.cache_resource(show_spinner=False)
def get_agent(use_reasoning_mode):
    """
    Khá»Ÿi táº¡o Agent. 
    Tham sá»‘ 'use_reasoning_mode' giÃºp Streamlit biáº¿t khi nÃ o cáº§n táº¡o láº¡i Agent má»›i.
    """
    print(f"ğŸ”„ Äang khá»Ÿi táº¡o NutriAgent vá»›i cháº¿ Ä‘á»™ Reasoning={use_reasoning_mode}...")
    return NutriAgentReseacher(use_reasoning=use_reasoning_mode)

# --- 5. SIDEBAR ---
with st.sidebar:
    st.markdown("### âš™ï¸ Cáº¥u hÃ¬nh NutriAgent")
    
    # NÃºt gáº¡t báº­t táº¯t cháº¿ Ä‘á»™ suy luáº­n
    is_reasoning = st.toggle("KÃ­ch hoáº¡t Suy luáº­n sÃ¢u (CoT)", value=True)
    
    st.divider()
    
    # NÃºt xÃ³a lá»‹ch sá»­
    if st.button("ğŸ—‘ï¸ Clear Chat", type="primary", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("""
    <div style='margin-top: 20px; font-size: 12px; color: grey;'>
    Supported by: <br>
    - Llama 3.3 (Groq)<br>
    - Qdrant VectorDB<br>
    - Advanced RAG
    - PDF Nutrition & Food Viet Nam Table VN
    - Phuong The Son <br>
    </div>
    """, unsafe_allow_html=True)

# Khá»Ÿi táº¡o Agent dá»±a trÃªn nÃºt gáº¡t
agent = get_agent(is_reasoning)

# Init session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 6. GIAO DIá»†N CHÃNH ---
st.markdown("""
    <div class="header-container">
        <div style="font-size: 50px;">ğŸ¥—</div>
        <h1 class="header-title">NutriAgent AI</h1>
        <p>Há»i Ä‘Ã¡p dinh dÆ°á»¡ng & Tra cá»©u thÃ nh pháº§n thá»±c pháº©m</p>
    </div>
""", unsafe_allow_html=True)

# Render lá»‹ch sá»­
for msg in st.session_state.messages:
    avatar = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¦œ"
    with st.chat_message(msg["role"], avatar=avatar):
        # Náº¿u lÃ  bot vÃ  cÃ³ pháº§n suy luáº­n (áº©n trong metadata) thÃ¬ hiá»ƒn thá»‹ láº¡i
        if msg["role"] == "assistant" and "thoughts" in msg and msg["thoughts"]:
            with st.expander("ğŸ¤” Xem quÃ¡ trÃ¬nh suy luáº­n"):
                st.info(msg["thoughts"])
        st.markdown(msg["content"])

# --- 7. Xá»¬ LÃ CHAT ---
if prompt := st.chat_input("VÃ­ dá»¥: 100g á»©c gÃ  chá»©a bao nhiÃªu protein?"):
    
    # 1. Hiá»ƒn thá»‹ User Message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.write(prompt)

    # 2. Xá»­ lÃ½ Assistant Message
    with st.chat_message("assistant", avatar="ğŸ¦œ"):
        
        # Chuyá»ƒn Ä‘á»•i lá»‹ch sá»­ chat (Bá» tin nháº¯n user vá»«a nháº­p Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p trong history)
        lc_history = convert_history_to_langchain(st.session_state.messages[:-1])
        
        # Container hiá»ƒn thá»‹ tráº¡ng thÃ¡i
        with st.status("NutriAgent Ä‘ang nghiÃªn cá»©u...", expanded=True) as status:
            st.write("ğŸ” Äang tÃ¬m kiáº¿m trong VectorDB...")
            # Gá»i Agent
            response = agent.research(prompt, chat_history=lc_history)
            
            st.write("Äang tá»•ng há»£p cÃ¢u tráº£ lá»i...")
            status.update(label="ÄÃ£ xong!", state="complete", expanded=False)
        
        # --- A. HIá»‚N THá»Š SUY LUáº¬N (Náº¿u cÃ³) ---
        thoughts = response.get("model_thoughts", "")
        if is_reasoning and thoughts:
            with st.expander("ğŸ¤” Xem quÃ¡ trÃ¬nh suy luáº­n (Chain-of-Thought)"):
                st.info(thoughts)
        
        # --- B. HIá»‚N THá»Š CÃ‚U TRáº¢ Lá»œI ---
        st.markdown(response["answer"])
        
        # --- C. HIá»‚N THá»Š NGUá»’N ---
        sources = response.get("sources", [])
        if sources:
            st.divider()
            st.caption("ğŸ“š Nguá»“n tÃ i liá»‡u tham kháº£o:")
            
            # Xá»­ lÃ½ hiá»ƒn thá»‹ nguá»“n Ä‘áº¹p máº¯t
            unique_sources = {}
            for doc in sources:
                src_name = doc.metadata.get('source', 'TÃ i liá»‡u khÃ´ng tÃªn')
                # LÃ m sáº¡ch tÃªn file (bá» Ä‘Æ°á»ng dáº«n dÃ i dÃ²ng)
                short_name = src_name.split("/")[-1].replace(".pdf", "")
                unique_sources[short_name] = unique_sources.get(short_name, 0) + 1
            
            # Hiá»ƒn thá»‹ dáº¡ng Chips
            cols = st.columns(len(unique_sources))
            for idx, (name, count) in enumerate(unique_sources.items()):
                # DÃ¹ng HTML/CSS nhá» Ä‘á»ƒ hiá»ƒn thá»‹ badge
                st.markdown(f"""
                <div style="background-color: #f0fdf4; padding: 5px 10px; border-radius: 20px; border: 1px solid #bbf7d0; font-size: 12px; color: #166534; display: inline-block;">
                    ğŸ“„ {name} <span style="font-weight: bold;">(x{count} chunks)</span>
                </div>
                """, unsafe_allow_html=True)

    # 3. LÆ°u láº¡i vÃ o Session State (KÃ¨m cáº£ pháº§n suy luáº­n Ä‘á»ƒ render láº¡i náº¿u f5)
    st.session_state.messages.append({
        "role": "assistant", 
        "content": response["answer"],
        "thoughts": thoughts # LÆ°u thÃªm trÆ°á»ng nÃ y
    })