import os
import pickle
from llama_parse import LlamaParse
from typing import List
from langchain_core.documents import Document as LangChainDocument
from langchain_text_splitters import RecursiveCharacterTextSplitter
# Internal Import
from src.config import config 
from src.utils.helpers import fix_encoding, clean_broken_layout

class ProcessDocuments:
    def __init__(self):
        self.cache_dir = os.path.join(config.DATA_DIR, "cache_parse")
        os.makedirs(self.cache_dir, exist_ok=True)
    
    def _load_from_cache(self, cache_name):
        cache_path = os.path.join(self.cache_dir, f"{cache_name}.pkl")
        if os.path.exists(cache_path):
            print(f"Load cache_parse: {cache_name}")
            with open(cache_path, "rb") as f:
                return pickle.load(f)
        return None
    
    def _save_to_cache(self, documents, cache_name):
        cache_path = os.path.join(self.cache_dir, f"{cache_name}.pkl")
        with open(cache_path, "wb") as f:
            pickle.dump(documents, f)
        print(f"Saved cache_parse: {cache_name}")
    
    # H√†m ph·ª• tr·ª£ chuy·ªÉn ƒë·ªïi LlamaDoc -> LangChainDoc
    def _convert_to_langchain(self, llama_docs, source_name):
        langchain_docs = []
        for doc in llama_docs:
            lc_doc = LangChainDocument(
                page_content=doc.text, # L·∫•y n·ªôi dung text
                metadata={
                    "source": source_name,
                    **doc.metadata # Copy metadata g·ªëc
                }
            )
            langchain_docs.append(lc_doc)
        
        return langchain_docs

    def load_english_textbook(self):
        CACHE_NAME = "textbook_en_parsed"
        
        # Check cache
        cached = self._load_from_cache(CACHE_NAME)
        if cached: return cached

        print(f"Parsing TextBook EN...")
        parser = LlamaParse(
            api_key = config.LLAMA_CLOUD_API_KEY,
            result_type="markdown", 
            verbose=True, 
            language="en"
        )

        # load data sau khi parse              
        llama_docs = parser.load_data(config.PATH_TEXTBOOK_EN)
        
        # convert sang langchain
        final_docs = self._convert_to_langchain(llama_docs, "Human Nutrition Text")
        
        # Save cache
        self._save_to_cache(final_docs, CACHE_NAME)
        return final_docs

    def load_vietnamese_table(self):
        CACHE_NAME = "food_table_vn_parsed"
        
        # 1. Load file Cache c≈© l√™n
        docs = self._load_from_cache(CACHE_NAME)
        
        # --- [LOGIC T·ª∞ ƒê·ªòNG FIX V√Ä L∆ØU] ---
        if docs:
            print(f"üìÇ ƒê√£ t√¨m th·∫•y Cache '{CACHE_NAME}'. ƒêang ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu...")
            count_fixed = 0
            is_modified = False 
            
            for doc in docs:
                original_text = doc.page_content
                
                # G·ªçi h√†m s·ª≠a l·ªói
                fixed_text = fix_encoding(original_text)
                cleaned_text = clean_broken_layout(fixed_text)
                
                # N·∫øu c√≥ thay ƒë·ªïi th√¨ c·∫≠p nh·∫≠t
                if original_text != cleaned_text:
                    doc.page_content = cleaned_text
                    count_fixed += 1
                    is_modified = True 
            
            if count_fixed > 0:
                print(f"ƒê√£ t·ª± ƒë·ªông s·ª≠a l·ªói hi·ªÉn th·ªã cho {count_fixed} trang t√†i li·ªáu.")
            
            if is_modified:
                self._save_to_cache(docs, CACHE_NAME)
                print("ƒê√£ l∆∞u Cache m·ªõi! L·∫ßn sau load s·∫Ω kh√¥ng c·∫ßn s·ª≠a n·ªØa.")
            else:
                print("D·ªØ li·ªáu trong Cache ƒë√£ s·∫°ch ƒë·∫πp. Kh√¥ng c·∫ßn x·ª≠ l√Ω th√™m.")

            return docs

        # --- TR∆Ø·ªúNG H·ª¢P KH√îNG C√ì CACHE (Parse m·ªõi t·ª´ ƒë·∫ßu) ---
        print(f"Kh√¥ng th·∫•y Cache. B·∫Øt ƒë·∫ßu Parse Food Table VN t·ª´ LlamaCloud...")
        parser = LlamaParse(
            api_key = config.LLAMA_CLOUD_API_KEY,
            result_type="markdown",
            user_prompt="ƒê√¢y l√† b·∫£ng dinh d∆∞·ª°ng. Chuy·ªÉn th√†nh Markdown Table chu·∫©n. L·∫∑p l·∫°i header.",
            verbose=True,
            language="vi"
        )

        llama_docs = parser.load_data(config.PATH_FOOD_TABLE_VN)
        
        # Convert sang LangChain
        final_docs = self._convert_to_langchain(llama_docs, "Vietnamese Food Table")
        for doc in final_docs:
            doc.page_content = fix_encoding(doc.page_content)
            doc.page_content = clean_broken_layout(doc.page_content)

        # L∆∞u cache l·∫°i
        self._save_to_cache(final_docs, CACHE_NAME)
        
        return final_docs


class TextSplitter:
    def __init__(self, chunk_size: int = config.CHUNK_SIZE, chunk_overlap: int = config.CHUNK_OVERLAP):
        
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            separators=["\n\n", "\n", "|", "##", " ", ""] 
        )

    def split(self, documents : List[str]):
        chunks = self.splitter.split_documents(documents)
        return chunks